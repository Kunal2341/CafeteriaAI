{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import psutil\n",
    "import random\n",
    "import datetime\n",
    "from pprint import pprint\n",
    "#--------\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed()\n",
    "now = str(datetime.datetime.now())\n",
    "now = now[:10] +\"_\"+ str(round(random.random(),3) )\n",
    "#---\n",
    "base_dir ='/Users/kunal/Documents/AI/Cafeteria/CorrectCopy/Data_PreProcess/'\n",
    "os.chdir(base_dir)\n",
    "#---\n",
    "def extract_image_one_fps(video_source_path):\n",
    "    vidcap = cv2.VideoCapture(video_source_path)\n",
    "    count = 0\n",
    "    success = True\n",
    "    while success:\n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC,(count*1000)) # 2 second***   \n",
    "        success,image = vidcap.read()\n",
    "        image_last = cv2.imread(\"frame{}.png\".format(count-1))\n",
    "        if np.array_equal(image, image_last):\n",
    "            break\n",
    "        cv2.imwrite(\"frame%d.png\" % count, image)     # save frame as PNG file\n",
    "        print( '{}.sec reading a new frame:{}'.format(count,success))\n",
    "        count += 1\n",
    "#------ # record and convert to still images\n",
    "#---#student_name = input()\n",
    "student_name = 'CAFETERIA'+\"__\" + now\n",
    "#---\n",
    "if not os.path.exists(student_name):\n",
    "        os.makedirs(student_name)\n",
    "#---\n",
    "nm1 = str(student_name)\n",
    "nm3 = '.mp4'\n",
    "mp4_file = \"\".join((nm1, nm3))\n",
    "#----\n",
    "os.chdir(os.path.join('/Users/kunal/Documents/AI/Cafeteria/CorrectCopy/Data_PreProcess/', student_name) )\n",
    "#----\n",
    "frames_per_second = 10    # 24.0 # HIGHER NUMBER LOWER # OF FRAMES!\n",
    "#----\n",
    "#my_res = '480p'\n",
    "my_res = '720p'\n",
    "#----\n",
    "STD_DIMENSIONS = {\n",
    "    \"480p\": (640, 480),\n",
    "    \"720p\": (1280, 720),\n",
    "    \"1080p\": (1920, 1080),\n",
    "    \"4k\": (3840, 2160),\n",
    "}\n",
    "# Video encoding, see www.fourcc.org/codecs.php for more codecs\n",
    "VIDEO_TYPE = {\n",
    "    'avi': cv2.VideoWriter_fourcc(*'XVID'),\n",
    "    'mp4': cv2.VideoWriter_fourcc(*'XVID'),\n",
    "}\n",
    "#---\n",
    "def get_video_type(filename):\n",
    "    filename, ext = os.path.splitext(filename)\n",
    "    if ext in VIDEO_TYPE:\n",
    "        return VIDEO_TYPE[ext]\n",
    "    return VIDEO_TYPE['avi']\n",
    "#---\n",
    "#def set_res(cap, res='480p'):\n",
    "def set_res(cap, res='720p'):    \n",
    "    #width, height = STD_DIMENSIONS['480p']\n",
    "    width, height = STD_DIMENSIONS['720p']\n",
    "    if res in STD_DIMENSIONS:\n",
    "        width, height = STD_DIMENSIONS[res]\n",
    "    cap.set(3, width)\n",
    "    cap.set(4, height)\n",
    "    return width, height\n",
    "#---\n",
    "recording_length = 5\n",
    "cap = cv2.VideoCapture(0)\n",
    "t0 = time.time()\n",
    "#---\n",
    "dims = set_res(cap, my_res)\n",
    "video_type_cv2 = get_video_type(mp4_file)\n",
    "#---\n",
    "mp4_out = cv2.VideoWriter(mp4_file, video_type_cv2, frames_per_second, dims)\n",
    "#---\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    mp4_out.write(frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    if time.time() > (t0 + recording_length) or  cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "mp4_out.release()\n",
    "cv2.destroyAllWindows()\n",
    "#-----\n",
    "#extract_image_one_fps(os.path.join(base_dir,  student_name, mp4_file ) )\n",
    "#-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Folder to save video *new\n",
    "os.chdir(os.path.join('/Users/kunal/Documents/AI/Cafeteria/CorrectCopy/Data_PreProcess/', student_name))\n",
    "base_dir =os.path.join('/Users/kunal/Documents/AI/Cafeteria/CorrectCopy/Data_PreProcess/', student_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_image_one_fps(video_source_path):\n",
    "    vidcap = cv2.VideoCapture(video_source_path)\n",
    "    count = 0\n",
    "    success = True\n",
    "    while success:\n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC,(count*1000)) # 2 second***   \n",
    "        success,image = vidcap.read()\n",
    "        ## Stop when last frame is identified\n",
    "        image_last = cv2.imread(\"frame{}.png\".format(count-1))\n",
    "        if np.array_equal(image, image_last):\n",
    "            break\n",
    "        cv2.imwrite(\"frame%d.png\" % count, image)     # save frame as PNG file\n",
    "        print( '{}.sec reading a new frame:{}'.format(count,success))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to detect face using OpenCV\n",
    "def detect_face(img):\n",
    "    #convert the test image to gray image as opencv face detector expects gray images\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #load OpenCV face detector, I am using LBP which is fast\n",
    "    #there is also a more accurate but slow Haar classifier\n",
    "    face_cascade = cv2.CascadeClassifier('/Users/kunal/Documents/AI/Cafeteria/OpenCV-Python-Series-master/src_final/lbpcascades/lbpcascade_frontalface.xml')\n",
    "    #let's detect multiscale (some images may be closer to camera than others) images\n",
    "    #result is a list of faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5)\n",
    "    #if no faces are detected then return original img\n",
    "    if (len(faces) == 0):\n",
    "        return None, None\n",
    "    #under the assumption that there will be only one face,\n",
    "    #extract the face area\n",
    "    (x, y, w, h) = faces[0]\n",
    "    #return only the face part of the image\n",
    "    return gray[y:y+w, x:x+h], faces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIDEO TO FACE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kunal/Documents/AI/Cafeteria/CorrectCopy/Data_PreProcess/CAFETERIA__2019-10-28_0.259'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path = (base_dir)\n",
    "videos = os.listdir(base_dir)\n",
    "if '.DS_Store' in videos: videos.remove('.DS_Store')        \n",
    "video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.sec reading a new frame:True\n",
      "1.sec reading a new frame:True\n",
      "2.sec reading a new frame:True\n",
      "3.sec reading a new frame:True\n",
      "4.sec reading a new frame:True\n",
      "5.sec reading a new frame:True\n",
      "6.sec reading a new frame:True\n",
      "7.sec reading a new frame:True\n",
      "8.sec reading a new frame:False\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) C:\\projects\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1658: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3cfb33ddc038>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphoto_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFRAMES\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m#tmp = rotate_image(tmp, 270) # DONT ROTATE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mface\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_face\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mimg_nm\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mvideos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".png\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-ef45930dd510>\u001b[0m in \u001b[0;36mdetect_face\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#let's detect multiscale (some images may be closer to camera than others) images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#result is a list of faces\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaleFactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminNeighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m#if no faces are detected then return original img\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.0) C:\\projects\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1658: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for i in range(len(videos)):\n",
    "    os.listdir(os.path.join(video_path) )\n",
    "\n",
    "    os.chdir(os.path.join(video_path))\n",
    "\n",
    "    '''\n",
    "    X = os.listdir(\".\")\n",
    "    if '.DS_Store' in X: X.remove('.DS_Store')\n",
    "    X[0]\n",
    "    '''\n",
    "    extract_image_one_fps(os.path.join(video_path, videos[i]) ) \n",
    "\n",
    "    # cleanup 2 #zero bytes file\n",
    "    for filename in os.listdir(os.path.join(video_path) ):\n",
    "         if os.path.getsize(filename) == 0:\n",
    "                os.remove(filename) \n",
    "\n",
    "    os.chdir(os.path.join(video_path))\n",
    "    photo_path = os.path.join(video_path)\n",
    "    face_frames = os.listdir(os.path.join(video_path))\n",
    "    if '.DS_Store' in face_frames: face_frames.remove('.DS_Store')\n",
    "\n",
    "\n",
    "    # Video file removed\n",
    "    for face_frames1 in face_frames:#os.listdir(os.path.join(video_in, student_name)):\n",
    "        if face_frames1.endswith(\"mp4\") or  face_frames1.endswith(\"avi\"):\n",
    "            os.remove(face_frames1) \n",
    "\n",
    "    face_frames = os.listdir(os.path.join(video_path))\n",
    "    if '.DS_Store' in face_frames: face_frames.remove('.DS_Store')        \n",
    "\n",
    "    k=0\n",
    "    for FRAMES in face_frames:\n",
    "        tmp = cv2.imread(os.path.join(photo_path, FRAMES) )\n",
    "        #tmp = rotate_image(tmp, 270) # DONT ROTATE\n",
    "        face, rect = detect_face(tmp)\n",
    "        k += 1\n",
    "        img_nm =  videos[i] + str(k) + \".png\"\n",
    "        cv2.imwrite(img_nm, face)\n",
    "\n",
    "    # Frames removed\n",
    "    for filename in os.listdir(os.path.join(video_path) ):\n",
    "        if filename.startswith(\"frame\"):\n",
    "            os.remove(filename) \n",
    "\n",
    "    # cleanup 2 #zero bytes file\n",
    "    for filename in os.listdir(os.path.join(video_path) ):\n",
    "         if os.path.getsize(filename) == 0:\n",
    "                os.remove(filename) \n",
    "                print(\"File Removed!\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
